A Home Assistant-Inspired Automation Runner for Unity: A Technical Deep-DiveSection 1: Architectural Blueprint for a Decampled Automation SystemThis section establishes the foundational architecture for a declarative, event-driven automation system within the Unity engine. By deconstructing the robust model pioneered by Home Assistant and implementing it through the proven Rule Engine design pattern, this blueprint outlines a framework that is inherently extensible, maintainable, and testable. This approach moves beyond traditional, tightly-coupled game logic, creating a scalable solution suitable for complex, dynamic interaction systems, particularly in a Virtual Reality (VR) context.1.1 Deconstructing the Home Assistant Model for a Game Engine ContextThe core inspiration for this system is the automation paradigm popularized by Home Assistant, which is built upon a simple yet powerful triad: triggers, conditions, and actions.1 This model provides a declarative framework for describing complex behaviors. Instead of writing imperative code that details how a process should unfold, a declarative rule simply states what should happen under specific circumstances.3 This separation of intent from implementation is not only cleaner but is also exceptionally well-suited for rules that may be defined externally or generated by tools like Large Language Models (LLMs).An automation rule is initiated when any of its specified triggers becomes true.2 Once triggered, the system evaluates a set of conditions. If all conditions are met (respecting logical operators), a sequence of actions is executed.1 To adapt this model for a game engine like Unity, we must map its core concepts to their in-game equivalents:Triggers: In Home Assistant, triggers are often tied to events like state changes (state), numeric values crossing a threshold (numeric_state), or specific occurrences (event).2 In a Unity context, these map directly to in-game events:A player pressing a controller button.An object entering a designated trigger volume.A character's health dropping below a certain percentage.A custom event broadcast by another game system.Conditions: Conditions act as gates, preventing actions from running unless the game world is in a desired state.4 Home Assistant supports a rich set of conditions, including logical checks (and, or, not), state validation, and numeric comparisons.6 These translate seamlessly to a game environment:Is the player holding a specific item?Is the target enemy within a certain range?Is the time of day currently "night"?Actions: Actions are the final output, modifying the state of the game world.1 A Home Assistant action might be a service call like light.turn_on.1 In Unity, this corresponds to invoking a method on a game object or system:Spawning a prefab.Playing a sound effect.Applying a force to a Rigidbody.Updating a value in a UI element.By adopting this trigger-condition-action structure, we establish a clear, logical flow for all automated behaviors within the application.1.2 Implementing the Rule Engine Design Pattern in C#The most effective way to implement the Home Assistant model in C# is through the Rule Engine design pattern. This behavioral pattern is specifically designed to replace complex, deeply nested conditional logic (i.e., "if-else chains") with a more manageable, object-oriented approach.7 It separates the rules themselves from the engine that evaluates them, promoting a clean separation of concerns and adhering to the Open/Closed Principleâ€”the system is open for extension (by adding new rules) but closed for modification (the core engine remains unchanged).7The foundation of this pattern lies in defining a set of common interfaces that represent the constituent parts of an automation. These interfaces form the contract for our entire system, ensuring that any new component can be seamlessly integrated as long as it adheres to the contract.IAutomation: This interface represents a single, complete automation rule. It acts as a container for its associated triggers, conditions, and actions.C#// Represents a complete, executable automation rule.
public interface IAutomation
{
    string Id { get; }
    string Alias { get; }
    AutomationMode Mode { get; }
    IReadOnlyList<ITrigger> Triggers { get; }
    IReadOnlyList<ICondition> Conditions { get; }
    IReadOnlyList<IAction> Actions { get; }
}
ITrigger: This interface defines the contract for any object that can initiate an automation. Its primary responsibility is to monitor an external state or event and notify the main automation engine when it fires.C#using System;

// Defines an entry point that can start an automation.
public interface ITrigger
{
    // Event invoked by the trigger when its criteria are met.
    // The IAutomation parameter tells the runner which rule was triggered.
    event Action<IAutomation, TriggerData> OnTriggered;

    // Called by the AutomationRunner to initialize the trigger.
    void Initialize(IAutomation parentAutomation);
}
ICondition: This interface represents a single conditional check. It evaluates the current state of the game world within a given context and returns a boolean value indicating whether the condition has passed.C#using Cysharp.Threading.Tasks;

// Defines a gatekeeper that evaluates the game state.
public interface ICondition
{
    // Asynchronously evaluates the condition.
    UniTask<bool> EvaluateAsync(ExecutionContext context);
}
IAction: This interface defines an executable task that modifies the game world. Its ExecuteAsync method contains the logic to be performed when an automation's triggers and conditions are all satisfied.C#using Cysharp.Threading.Tasks;

// Defines an operation to be performed on the game world.
public interface IAction
{
    // Asynchronously executes the action.
    UniTask ExecuteAsync(ExecutionContext context);
}
This interface-based design is the cornerstone of a flexible architecture. It allows for the creation of a diverse library of triggers, conditions, and actions that can be combined in countless ways, all without altering the core AutomationRunner that orchestrates them.71.3 The ExecutionContext: A Data-Flow StrategyTo maintain decoupling and allow information to flow from a trigger through to the conditions and actions, a dedicated data carrier object is required. This object, which we will call ExecutionContext, serves a purpose analogous to the trigger variable available in Home Assistant's templating system, which provides context about what initiated the automation.The ExecutionContext is a Plain Old C# Object (POCO) instantiated by the AutomationRunner when a trigger fires. It is then passed sequentially to each condition and action in the chain. This ensures that downstream components have access to relevant information without needing to know the specific type of trigger that started the process.A robust ExecutionContext should contain the following:C#using System.Collections.Generic;
using System.Threading;

// Carries state and data through an automation's execution pipeline.
public class ExecutionContext
{
    /// <summary>
    /// A reference to the game entity that was the primary subject of the trigger.
    /// For example, the player controller that pressed a button.
    /// </summary>
    public object TriggeringEntity { get; }

    /// <summary>
    /// A flexible data payload containing specific information from the trigger.
    /// For a numeric state trigger, this might contain 'from' and 'to' values.
    /// </summary>
    public TriggerData Data { get; }

    /// <summary>
    /// The cancellation token for this specific execution run.
    /// Used to gracefully stop long-running async actions.
    /// </summary>
    public CancellationToken CancellationToken { get; }

    // A shared dictionary for actions to pass data to subsequent actions.
    public Dictionary<string, object> SharedData { get; } = new Dictionary<string, object>();

    public ExecutionContext(object triggeringEntity, TriggerData data, CancellationToken cancellationToken)
    {
        TriggeringEntity = triggeringEntity;
        Data = data;
        CancellationToken = cancellationToken;
    }
}

// A generic container for trigger-specific data.
public class TriggerData
{
    public string TriggerId { get; }
    public IReadOnlyDictionary<string, object> Payload { get; }

    public TriggerData(string triggerId, IReadOnlyDictionary<string, object> payload)
    {
        TriggerId = triggerId;
        Payload = payload;
    }
}
The inclusion of a CancellationToken is of paramount importance. It is the mechanism that enables the AutomationRunner to gracefully cancel an in-flight execution, a feature that is essential for implementing advanced automation modes like restart. This data-flow strategy ensures that the entire system remains modular and that each component operates on a well-defined context, rather than reaching out into the global state to find the information it needs.Section 2: Data-Driven Rules via JSON and Polymorphic DeserializationThe power of this automation system stems from its data-driven nature. Rules are not hard-coded in C# but are defined in external JSON files, allowing for dynamic behavior that can be authored by designers, generated by tools, or even modified at runtime. This section details the critical bridge between the declarative JSON rule definitions and the executable C# object model, focusing on a robust and secure deserialization strategy.2.1 Designing a Flexible JSON SchemaA well-defined JSON schema is the contract between the data source (e.g., an LLM, a designer's tool) and the C# engine. It must be predictable, readable, and capable of representing the full spectrum of triggers, conditions, and actions our system supports. The schema should directly mirror the structure of our C# interfaces.A root Automation object in JSON will be structured as follows, drawing inspiration from Home Assistant's YAML configuration 4:JSON{
  "id": "VR_GrabObject_RightHand",
  "alias": "Grab Object When Grip Pressed (Right Hand)",
  "description": "Attaches the nearest grabbable object to the right hand when the grip button is pressed.",
  "mode": "restart",
  "triggers":,
  "conditions":,
  "actions":
}
Key elements of this schema include:id: A unique string to identify the automation for logging and state management.alias: A human-readable name.mode: Controls concurrent execution behavior (single, restart, queued, parallel).4triggers, conditions, actions: Arrays of objects, where each object represents a concrete implementation of the corresponding interface.type: A crucial discriminator field. This simple string identifier (e.g., "input_state", "proximity", "attach_object") tells the deserializer which specific C# class to instantiate for that object. This approach is fundamental to achieving polymorphism from a generic data format.2.2 Implementing Robust Deserialization with Newtonsoft.JsonThe central technical challenge is to convert the JSON arrays of abstract types (like triggers) into a C# List<ITrigger> populated with concrete instances (InputStateTrigger, etc.). This is known as polymorphic deserialization. While Newtonsoft.Json is a powerful library, selecting the correct strategy is an architectural decision with significant implications for security, coupling, and maintainability.Method 1: TypeNameHandling (The Simpler, but Flawed Approach)Newtonsoft.Json provides a built-in mechanism called TypeNameHandling.12 By setting TypeNameHandling.Objects or TypeNameHandling.Auto in the JsonSerializerSettings, the serializer will embed a special $type property in the JSON output. This property contains the full assembly-qualified name of the C# type.Example JSON with $type:JSON{
  "$type": "MyGame.Automations.InputStateTrigger, MyGame.Assembly",
  "platform": "oculus",
  "control": "RIndexTrigger"
}
Implementation:C#var settings = new JsonSerializerSettings
{
    TypeNameHandling = TypeNameHandling.Objects
};
var automation = JsonConvert.DeserializeObject<Automation>(jsonText, settings);
While this method is simple to implement, it suffers from two major drawbacks:Tight Coupling: The JSON data is now directly tied to the C# class names and assembly structure. If a developer refactors InputStateTrigger to InputButtonTrigger, all existing JSON files that use it will break.Security Vulnerability: This is the most critical issue. If the JSON is sourced from an untrusted or external source (like an LLM), a malicious actor could craft a JSON payload with a $type property that points to a dangerous class within the application's dependencies. Upon deserialization, the application would unknowingly instantiate this malicious object, potentially leading to a remote code execution vulnerability.12Method 2: Custom JsonConverter (The Superior, Secure Approach)A far more robust and secure solution is to implement a custom JsonConverter.13 This approach leverages the type discriminator field we designed into our schema. The converter reads the value of this field and uses a predefined, safe mapping to decide which concrete C# class to instantiate. This gives us complete control over the deserialization process and decouples the JSON contract from the internal code structure.The following is an abstract base converter that can be extended for triggers, conditions, and actions:C#using Newtonsoft.Json;
using Newtonsoft.Json.Linq;
using System;
using System.Collections.Generic;

public abstract class TypeDiscriminatorConverter<T> : JsonConverter
{
    // A mapping from the 'type' string in JSON to the concrete C# Type.
    protected abstract IReadOnlyDictionary<string, Type> TypeMap { get; }

    public override bool CanConvert(Type objectType) => objectType == typeof(T);
    public override bool CanWrite => false; // This converter is only for deserialization.

    public override object ReadJson(JsonReader reader, Type objectType, object existingValue, JsonSerializer serializer)
    {
        JObject jo = JObject.Load(reader);
        
        // Read the discriminator field.
        string typeName = jo["type"]?.Value<string>();
        if (string.IsNullOrEmpty(typeName))
        {
            throw new JsonSerializationException("Missing 'type' discriminator property.");
        }

        // Look up the corresponding C# Type from our safe map.
        if (!TypeMap.TryGetValue(typeName, out Type concreteType))
        {
            throw new JsonSerializationException($"Unknown type discriminator: {typeName}");
        }

        // Create an instance of the target type and populate it from the JSON object.
        object instance = Activator.CreateInstance(concreteType);
        serializer.Populate(jo.CreateReader(), instance);
        return instance;
    }

    public override void WriteJson(JsonWriter writer, object value, JsonSerializer serializer)
    {
        throw new NotImplementedException();
    }
}
This base class can then be easily implemented for each of our polymorphic types. For example, the ActionConverter:C#using System;
using System.Collections.Generic;

public class ActionConverter : TypeDiscriminatorConverter<IAction>
{
    protected override IReadOnlyDictionary<string, Type> TypeMap => new Dictionary<string, Type>
    {
        { "attach_object", typeof(AttachObjectAction) },
        { "debug_log", typeof(DebugLogAction) },
        { "delay", typeof(DelayAction) },
        { "wait_until", typeof(WaitUntilAction) }
        // Add all other safe, known action types here.
    };
}
Finally, to use these converters, they are added to the JsonSerializerSettings:C#var settings = new JsonSerializerSettings
{
    Converters = new List<JsonConverter>
    {
        new TriggerConverter(),
        new ConditionConverter(),
        new ActionConverter()
    }
};
var automations = JsonConvert.DeserializeObject<List<Automation>>(jsonText, settings);
This approach creates a stable, versionable API contract with the JSON data. New action types can be added simply by updating the TypeMap. It is secure because only types explicitly listed in the map can ever be instantiated, completely mitigating the risks associated with TypeNameHandling.2.3 Code Examples: JSON to C# ClassesTo make the system concrete, here are side-by-side examples of JSON definitions and their corresponding C# POCO classes.Condition Example: numeric_stateJSON Definition:JSON{
  "type": "numeric_state",
  "entity_id": "Player",
  "property": "Health",
  "below": 10.0
}
C# Class:C#using Newtonsoft.Json;

// A condition that checks if a numeric property of an entity is above or below a threshold.
public class NumericStateCondition : ICondition
{
    [JsonProperty("type")]
    public string Type { get; private set; }

    [JsonProperty("entity_id")]
    public string EntityId { get; private set; }

    [JsonProperty("property")]
    public string Property { get; private set; }

    [JsonProperty("above")]
    public float? Above { get; private set; }

    [JsonProperty("below")]
    public float? Below { get; private set; }

    public async UniTask<bool> EvaluateAsync(ExecutionContext context)
    {
        // Implementation would use a service to find the entity by 'EntityId'
        // and use reflection or an interface to get the 'Property' value.
        // For now, we'll return a placeholder.
        // bool result =...
        // return UniTask.FromResult(result);
        return await UniTask.FromResult(true); // Placeholder
    }
}
Action Example: debug_logJSON Definition:JSON{
  "type": "debug_log",
  "message": "Player health is critical! Triggered by {context.trigger.id}"
}
C# Class:C#using Newtonsoft.Json;
using UnityEngine;

// An action that prints a message to the Unity console.
public class DebugLogAction : IAction
{
    [JsonProperty("type")]
    public string Type { get; private set; }

    [JsonProperty("message")]
    public string Message { get; private set; }

    public UniTask ExecuteAsync(ExecutionContext context)
    {
        // A simple templating mechanism could be added here to substitute context variables.
        string formattedMessage = Message.Replace("{context.trigger.id}", context.Data.TriggerId);
        Debug.Log($"[Automation] {formattedMessage}");
        return UniTask.CompletedTask;
    }
}
These examples illustrate the direct mapping from the JSON data structure to strongly-typed C# objects, enabled by the custom JsonConverter.Section 3: The Automation Runner: Core Engine ImplementationWith the architectural blueprint and data model defined, this section details the construction of the system's core: the AutomationRunner. This is a non-MonoBehaviour service that acts as the central orchestrator, responsible for loading, managing, and executing the full lifecycle of every automation rule. Its design must account for concurrency, state management, and robust error handling to function as a reliable engine.3.1 The AutomationRunner ServiceThe AutomationRunner is a POCO C# class designed to be instantiated and managed by a Dependency Injection (DI) container. It encapsulates all the logic for the automation system, exposing a clean API to the rest of the application.Its primary responsibilities are:Rule Loading and Initialization: At application startup, the runner loads all .json files from a designated directory, deserializes them into a collection of IAutomation objects using the polymorphic JsonConverters, and initializes all their triggers.State Management: It maintains a registry of all loaded automations and tracks the state of any currently executing instances. This is crucial for implementing the various execution modes.Event Subscription: It acts as the central hub where triggers report their activation. When a trigger fires, it calls a method on the runner, initiating the execution pipeline for the associated automation.C#using System.Collections.Generic;
using System.Linq;

// The central service that manages and executes all automation rules.
public class AutomationRunner
{
    private readonly IReadOnlyList<IAutomation> _automations;
    private readonly Dictionary<string, CancellationTokenSource> _runningAutomations = new();

    // Injected dependency for loading rules.
    public AutomationRunner(IRuleLoader ruleLoader)
    {
        _automations = ruleLoader.LoadAllRules();
        InitializeTriggers();
    }

    private void InitializeTriggers()
    {
        foreach (var automation in _automations)
        {
            foreach (var trigger in automation.Triggers)
            {
                // Subscribe to the trigger's event.
                trigger.OnTriggered += HandleTriggerFired;
                trigger.Initialize(automation);
            }
        }
    }

    private void HandleTriggerFired(IAutomation automation, TriggerData data)
    {
        // This is the entry point for the execution pipeline.
        // We use.Forget() because this is a top-level async call.
        // Error handling should be done inside ExecuteAutomationAsync.
        ExecuteAutomationAsync(automation, data).Forget();
    }

    // The rest of the execution logic will be detailed below.
    //...
}
3.2 The Execution PipelineWhen HandleTriggerFired is called, the runner begins the asynchronous execution pipeline for the given automation. This process is orchestrated entirely with UniTask to ensure the game's main thread is never blocked.The pipeline follows these distinct steps:Handle Concurrency: The first step is to check the automation's mode and consult the _runningAutomations registry to decide if this new execution should proceed, be ignored, or if a previous run should be canceled.Create Execution Context: If the execution proceeds, a new CancellationTokenSource is created for this specific run, and an ExecutionContext is instantiated, populated with data from the trigger and the new cancellation token.Evaluate Conditions: The runner iterates through the automation's ICondition list. It awaits the result of each EvaluateAsync method. By default, all conditions must return true (an AND relationship). If any condition fails, the pipeline is aborted, and the actions are not executed. The implementation can be extended to support or and not logical containers.Execute Actions: If all conditions pass, the runner iterates through the IAction list, awaiting each ExecuteAsync method in sequence. This ensures that actions are performed in the order they are defined in the JSON.Cleanup: Once all actions are complete (or if the pipeline was aborted or canceled), the automation's ID and CancellationTokenSource are removed from the _runningAutomations registry to signify that it has finished.3.3 Handling Automation ModesImplementing the execution modes defined by Home Assistant transforms the runner from a simple event processor into a sophisticated state machine.4 This is a critical feature for creating predictable and reliable automations in a dynamic game environment. The logic is managed within the ExecuteAutomationAsync method before the main pipeline begins.C#private async UniTask ExecuteAutomationAsync(IAutomation automation, TriggerData data)
{
    // --- 1. Handle Concurrency based on Mode ---
    if (_runningAutomations.ContainsKey(automation.Id))
    {
        switch (automation.Mode)
        {
            case AutomationMode.Single:
                // Already running, so ignore this trigger.
                Debug.LogWarning($"[Automation] '{automation.Alias}' was triggered but is already running (mode: single). Ignoring.");
                return;

            case AutomationMode.Restart:
                // Already running, so cancel the previous run.
                Debug.Log($"[Automation] '{automation.Alias}' was triggered. Restarting previous run.");
                _runningAutomations[automation.Id].Cancel();
                _runningAutomations.Remove(automation.Id);
                break;

            case AutomationMode.Queued:
                // This mode is more complex and would require a queueing system.
                // For this implementation, we'll treat it as 'single'.
                Debug.LogWarning($"[Automation] '{automation.Alias}' triggered while running (mode: queued). Queuing not implemented, ignoring.");
                return;
            
            case AutomationMode.Parallel:
                // Do nothing, a new parallel execution will be created.
                break;
        }
    }

    var cts = new CancellationTokenSource();
    // For parallel mode, we need a unique key. For others, the automation ID is sufficient.
    string runId = automation.Mode == AutomationMode.Parallel? $"{automation.Id}_{Guid.NewGuid()}" : automation.Id;
    _runningAutomations.Add(runId, cts);

    try
    {
        // --- 2. Create Execution Context ---
        // The 'TriggeringEntity' would be resolved by a service based on trigger data.
        var context = new ExecutionContext(triggeringEntity: null, data, cts.Token);

        // --- 3. Evaluate Conditions ---
        foreach (var condition in automation.Conditions)
        {
            if (!await condition.EvaluateAsync(context))
            {
                Debug.Log($"[Automation] '{automation.Alias}' condition failed. Aborting.");
                return; // Abort execution
            }
        }

        // --- 4. Execute Actions ---
        Debug.Log($"[Automation] '{automation.Alias}' triggered and conditions passed. Executing actions.");
        foreach (var action in automation.Actions)
        {
            await action.ExecuteAsync(context);
        }
    }
    catch (OperationCanceledException)
    {
        Debug.Log($"[Automation] '{automation.Alias}' execution was canceled.");
    }
    catch (Exception ex)
    {
        Debug.LogError($"[Automation] Error executing '{automation.Alias}': {ex}");
    }
    finally
    {
        // --- 5. Cleanup ---
        if (_runningAutomations.TryGetValue(runId, out var storedCts))
        {
            storedCts.Dispose();
            _runningAutomations.Remove(runId);
        }
    }
}
This stateful management of running instances is the key architectural element that enables complex, real-world behaviors. A simple, stateless "fire-and-forget" approach would be insufficient for anything beyond the most basic automations. For example, the restart mode is essential for interactions like a motion-activated light that should reset its "turn off" timer every time new motion is detected. Without the runner actively tracking and canceling the previous timer task, the light would turn off prematurely. This demonstrates that the mode is not a peripheral feature but a core design concern that dictates the runner's internal state management strategy.Section 4: Mastering Asynchronicity with UniTaskThe user's requirement to use UniTask is a well-informed choice for a high-performance Unity application. Asynchronous operations are fundamental to creating responsive experiences, especially for automation rules that involve delays, waiting for game states, or performing sequences of actions over time. This section details the deep integration of UniTask into our architecture, focusing on non-blocking execution, robust cancellation, and the implementation of essential asynchronous actions.4.1 Integrating UniTask for Non-Blocking ExecutionIn Unity, long-running operations must not block the main thread, as this would cause the entire application to freeze. While Unity's native solution is Coroutines, and standard C# offers System.Threading.Tasks.Task, UniTask provides a superior alternative specifically tailored for the engine.14 Its key advantages include:Zero Garbage Collection (GC) Allocation: On its "hot path," UniTask operations are struct-based and avoid heap allocations, which is critical for preventing performance stutters caused by the garbage collector.15Main Thread Synchronization: UniTask operations, by default, resume on the Unity main thread, eliminating the need for manual context switching when interacting with Unity APIs (which can only be called from the main thread).14Rich, Unity-Specific API: It provides a wealth of extension methods and helpers for working with Unity's lifecycle, animations, and asynchronous operations.17To leverage these benefits, our core interfaces for conditions and actions were designed from the outset to be asynchronous:async UniTask<bool> ICondition.EvaluateAsync(ExecutionContext context)async UniTask IAction.ExecuteAsync(ExecutionContext context)This design ensures that any condition or action can perform long-running work without blocking. For example, a condition could perform a complex physics query, or an action could animate an object over several seconds. The AutomationRunner's execution pipeline, being fully async, seamlessly awaits these operations, yielding control back to the Unity engine and maintaining a smooth frame rate.4.2 Implementing Core Asynchronous ActionsWith the async foundation in place, we can implement powerful, time-based actions that are common in automation scenarios.DelayAction: This action pauses the execution of the automation's action sequence for a specified duration. It is the asynchronous equivalent of a wait command.C#using Cysharp.Threading.Tasks;
using Newtonsoft.Json;
using System;

public class DelayAction : IAction
{
    [JsonProperty("type")]
    public string Type { get; private set; }

    [JsonProperty("duration_seconds")]
    public float Duration { get; private set; }

    public async UniTask ExecuteAsync(ExecutionContext context)
    {
        try
        {
            await UniTask.Delay(TimeSpan.FromSeconds(Duration), cancellationToken: context.CancellationToken);
        }
        catch (OperationCanceledException)
        {
            // The delay was canceled, which is an expected outcome.
            // Re-throw to allow the runner to handle it.
            throw;
        }
    }
}
WaitUntilAction: A more advanced action that pauses the sequence until a specified in-game condition becomes true. This is a powerful primitive for creating reactive behaviors that depend on the evolving game state. This would typically be paired with a condition object defined in the JSON.C#using Cysharp.Threading.Tasks;
using Newtonsoft.Json;

public class WaitUntilAction : IAction
{
    [JsonProperty("type")]
    public string Type { get; private set; }

    // This would be deserialized into a concrete ICondition instance.
    [JsonProperty("condition")]
    [JsonConverter(typeof(ConditionConverter))]
    public ICondition ConditionToMeet { get; private set; }

    public async UniTask ExecuteAsync(ExecutionContext context)
    {
        // Poll the condition until it evaluates to true.
        await UniTask.WaitUntil(() => ConditionToMeet.EvaluateAsync(context).GetAwaiter().GetResult(),
                                cancellationToken: context.CancellationToken);
    }
}
4.3 Advanced Cancellation and Timeout ManagementThe most critical aspect of a robust asynchronous system is disciplined lifecycle management, specifically cancellation. An automation, once started, must be reliably stoppable. This is not an optional feature but a core requirement for stability, especially when using modes like restart.The CancellationToken carried by the ExecutionContext is the sole mechanism for achieving this. It must be diligently passed down through every async call chain. When the AutomationRunner needs to stop a running automation (e.g., because a restart was triggered), it calls Cancel() on the CancellationTokenSource associated with that run. This action has a cascading effect:The CancellationTokenSource sets its token to the "canceled" state.Any UniTask operation currently being awaited that was passed this token (like UniTask.Delay or UniTask.WaitUntil) will immediately throw an OperationCanceledException.This exception propagates up the await stack, unwinding the execution cleanly.The AutomationRunner's top-level try...catch block catches this exception, logs that the automation was canceled, and proceeds to its finally block for cleanup.This disciplined "token passing" is the architectural backbone that prevents "leaked" or "zombie" tasks.18 Without it, canceling an automation would be impossible. A task started for a delay would continue running in the background even after its parent automation was supposedly stopped, leading to unpredictable behavior and resource leaks. The explicit management of cancellation tokens, as demonstrated in the UniTask.WhenAny discussions, is the standard and required practice for writing reliable asynchronous code.18 This ensures that the AutomationRunner maintains absolute control over the lifecycle of every task it initiates.Section 5: System Integration: Input Sources and Action TargetsThis section addresses the crucial integration points between the generic, self-contained automation engine and the specific context of the Unity VR application. To maintain a decoupled and testable architecture, we must create insulating layers that prevent the core engine from having direct knowledge of specific input SDKs or game logic implementations. This is achieved by applying the Adapter and Facade design patterns through service interfaces.5.1 Part I: Abstracting Input TriggersThe automation engine needs to react to player input from Meta Quest controllers, but it should not be tightly coupled to the OVRInput SDK or any other specific input system.19 A hard dependency would make the engine difficult to test in isolation and impossible to reuse in a project that uses a different input provider (e.g., Unity's Input System, OpenXR).To solve this, we apply the Dependency Inversion Principle by defining an IInputService interface. This interface defines a generic contract for providing input events, abstracting away the implementation details of the underlying SDK.The IInputService Interface and Data Structure:C#using System;

public enum InputState { Began, Performed, Canceled }

public readonly struct InputEvent
{
    public readonly string Device;
    public readonly string Control;
    public readonly InputState State;
    public readonly float Value;
    // Additional context like position/rotation could be added here.
}

public interface IInputService
{
    event Action<InputEvent> OnInputEvent;
}
The Concrete Implementation: OculusInputService:This class implements IInputService and contains the specific logic for polling the Oculus SDK. By also implementing VContainer's ITickable interface, we can ensure its Tick() method is called every frame by the DI container, allowing it to continuously monitor for input changes without being a MonoBehaviour.C#using System;
using System.Collections.Generic;
using VContainer.Unity;

public class OculusInputService : IInputService, ITickable
{
    public event Action<InputEvent> OnInputEvent;

    // A map of raw buttons to their previous state to detect changes.
    private readonly Dictionary<OVRInput.RawButton, bool> _buttonStates = new();

    public void Tick()
    {
        // Example for a single button: Right Index Trigger
        var control = OVRInput.RawButton.RIndexTrigger;
        bool isPressed = OVRInput.Get(control);
        _buttonStates.TryGetValue(control, out bool wasPressed);

        if (isPressed &&!wasPressed)
        {
            OnInputEvent?.Invoke(new InputEvent { Device = "Oculus", Control = control.ToString(), State = InputState.Began });
        }
        else if (!isPressed && wasPressed)
        {
            OnInputEvent?.Invoke(new InputEvent { Device = "Oculus", Control = control.ToString(), State = InputState.Canceled });
        }

        _buttonStates[control] = isPressed;

        // Similar logic would be added for all other relevant buttons and axes.
    }
}
The InputStateTrigger:Finally, our concrete InputStateTrigger class (which implements ITrigger) takes a dependency on IInputService via its constructor. During its Initialize phase, it subscribes to the OnInputEvent and fires its own OnTriggered event when it receives an event that matches its configuration from the JSON file. This completes the chain of decoupled communication: OculusInputService -> IInputService -> InputStateTrigger -> AutomationRunner.5.2 Part II: Mapping and Executing ActionsA similar challenge exists for executing actions. A JSON action like {"type": "spawn_prefab", "prefab_name": "Explosion"} needs to invoke a specific C# method in our game logic. A naive implementation would embed this game logic directly inside the action class, but this would tightly couple the generic action to a specific project's ResourceManager or Player class.A better approach is to use a dispatch system that maps string-based action identifiers to executable code. We will compare two common methods for this.Method 1: Reflection-Based DispatchThis method uses C#'s reflection capabilities to dynamically find and invoke a method on a target object based on string names provided in the JSON.20JSON Action: {"type": "service_call", "service": "PlayerService", "method": "Heal", "parameters": }Action Class (ServiceCallAction): This class would use reflection to find a registered service named "PlayerService", find a method on it named "Heal", and invoke it with the provided parameters.22Pros: Extremely flexible; new methods can be exposed without any registration code.Cons: Significantly slower performance due to reflection overhead, not type-safe (method names are "stringly-typed"), and can break silently if method names or signatures are refactored.20Method 2: Delegate/Command Registry (The Recommended Approach)A much more performant and robust solution is to create a central ActionRegistry service. Other systems in the application can register their capabilities with this registry at startup, mapping a public action ID to a C# Action or Func delegate.The ActionRegistry Service:C#using System;
using System.Collections.Generic;

public class ActionRegistry
{
    private readonly Dictionary<string, Func<ExecutionContext, JObject, UniTask>> _actions = new();

    public void Register(string actionId, Func<ExecutionContext, JObject, UniTask> action)
    {
        _actions[actionId] = action;
    }

    public UniTask Execute(string actionId, ExecutionContext context, JObject parameters)
    {
        if (_actions.TryGetValue(actionId, out var action))
        {
            return action.Invoke(context, parameters);
        }
        Debug.LogError($" No action registered with ID: {actionId}");
        return UniTask.CompletedTask;
    }
}
Registration (in a game-specific installer):C#// In a class like PlayerServiceInstaller
var registry = container.Resolve<ActionRegistry>();
var player = container.Resolve<Player>();

registry.Register("player.heal", (context, parameters) => 
{
    int amount = parameters["amount"].Value<int>();
    player.Heal(amount);
    return UniTask.CompletedTask;
});
The GenericAction Class:We can now have a single, generic IAction implementation that simply looks up its ID in the registry and executes the associated delegate.C#public class GenericAction : IAction
{
    private readonly ActionRegistry _registry;

    [JsonProperty("action")]
    public string ActionId { get; private set; }

    [JsonProperty("data")]
    public JObject Parameters { get; private set; }

    public GenericAction(ActionRegistry registry) { _registry = registry; }

    public UniTask ExecuteAsync(ExecutionContext context)
    {
        return _registry.Execute(ActionId, context, Parameters);
    }
}
This delegate-based approach is vastly superior for a production system. It is nearly as fast as a direct method call, is type-safe at the point of registration, and creates a clear, centralized manifest of all behaviors the automation system can invoke.Table: Action Dispatching Method ComparisonFeatureReflection-Based DispatchDelegate RegistryPerformanceSlower; involves runtime type lookup and method bindingHigh; delegate invocation is a direct memory pointer callType SafetyLow; relies on string matching for types and methodsHigh; registration involves strongly-typed lambda expressionsEase of AddingHigh; no registration needed, methods are found automaticallyModerate; requires explicit registration for each new actionRefactoring ResilienceLow; renaming a method in C# breaks all associated JSONHigh; renaming a method only breaks the single registration pointSecurityModerate; can be constrained but is inherently permissiveHigh; only explicitly registered actions can ever be executedThe IInputService and ActionRegistry act as critical insulating layers. They allow the core automation engine to remain completely agnostic of the specific game it is running in. This separation is the key to creating a system that is reusable, highly testable (as these services can be easily mocked), and architecturally clean, adhering to the principles of a layered architecture where inner layers do not depend on outer ones.23Section 6: A Pure C# Foundation: Dependency Injection with VContainerThe user's directive to avoid MonoBehaviour is a sophisticated architectural constraint that pushes the design away from Unity's default component model towards a more scalable and maintainable service-oriented architecture. This section explains why Dependency Injection (DI) is the essential enabling technology for such an architecture and justifies the selection of VContainer as the optimal framework for its implementation.6.1 Justifying Dependency Injection for a Non-MonoBehaviour ArchitectureIn a typical Unity project, MonoBehaviours serve two primary roles: they provide lifecycle callbacks (Awake, Start, Update) and they act as a service locator via GetComponent<T>().24 While convenient for simple projects, this pattern leads to several architectural problems in larger applications:Tight Coupling: Classes become tightly coupled to the scene hierarchy and to specific MonoBehaviour implementations. A class that calls GetComponent<PlayerController>() cannot be reused or tested without a PlayerController component existing on a GameObject in a scene.25Hidden Dependencies: It's not clear from a class's public API what its dependencies are. One must read the implementation code to find all the GetComponent or singleton calls.Testability Challenges: Unit testing classes that depend on the Unity engine and scene state is difficult and often requires complex test harnesses.The "God Object" Problem: The convenience of singletons and static managers often leads to the creation of massive "Manager" classes that accumulate unrelated responsibilities, violating the Single Responsibility Principle.26Dependency Injection inverts this model.27 Instead of a class actively finding its dependencies, the dependencies are provided to it (typically through its constructor). A central entity, the DI Container, is responsible for creating and "wiring up" the entire graph of objects at application startup.28 This approach yields a system of Plain Old C# Objects (POCOs) with clear, explicit dependencies, resulting in a codebase that is modular, loosely coupled, and highly testable.6.2 VContainer vs. Zenject: A Performance-Based ChoiceFor Unity, the two most prominent DI frameworks are Zenject and VContainer. While Zenject has been a long-standing solution, VContainer has emerged as the modern, high-performance choice for new projects.29A comparative analysis reveals several key advantages for VContainer:Performance: VContainer is significantly faster, with benchmarks showing its Resolve operations to be 5-10 times faster than Zenject's. This is crucial for performance-sensitive applications like VR.16GC Allocation: VContainer is designed for minimal garbage collection, achieving zero allocation in many common scenarios. Zenject, by contrast, is known to be more memory-intensive.16Simplicity and Code Size: VContainer has a smaller, more focused API and a lightweight internal implementation. Zenject is a larger, more complex framework with a steeper learning curve.29Development Status: VContainer is in active development, while Zenject and its successor, Extenject, have seen less recent activity.31Given these factors, VContainer is the clear choice for building a new, performant, non-MonoBehaviour architecture in Unity.26.3 Setting up the VContainer LifetimeScopeThe entry point for a VContainer application is a single MonoBehaviour that inherits from LifetimeScope. This component, often placed on a root object in the main scene, acts as the Composition Rootâ€”the one place in the application where the object graph is configured.33Inside the Configure method of a custom LifetimeScope, we register all our POCO services with the container builder. This tells VContainer how to create and manage the lifecycle of each service.C#using VContainer;
using VContainer.Unity;

public class AppLifetimeScope : LifetimeScope
{
    protected override void Configure(IContainerBuilder builder)
    {
        // Register the AutomationRunner as a singleton.
        // VContainer will create one instance and reuse it for all dependencies.
        builder.Register<AutomationRunner>(Lifetime.Singleton);

        // Register the rule loader and action registry.
        builder.Register<IRuleLoader, JsonFileRuleLoader>(Lifetime.Singleton);
        builder.Register<ActionRegistry>(Lifetime.Singleton);

        // Register the input service, binding the interface to a concrete implementation.
        builder.Register<IInputService, OculusInputService>(Lifetime.Singleton);

        // Register the OculusInputService itself so VContainer can call its ITickable.Tick method.
        // We also register it as an entry point to ensure it's created at startup.
        builder.RegisterEntryPoint<OculusInputService>();
    }
}
When the scene starts, this LifetimeScope will automatically build the container. It will analyze the constructors of each registered type, discover their dependencies (e.g., AutomationRunner depends on IRuleLoader), and instantiate and inject them in the correct order.6.4 Driving the System with VContainer Entry PointsThe most powerful feature of VContainer for a non-MonoBehaviour architecture is its system of entry points. This is the mechanism that bridges our pure C# services to the Unity engine's lifecycle loop, completely replacing the need for MonoBehaviour's Awake, Start, and Update methods.33This is achieved through a set of marker interfaces. When VContainer builds its container, it scans all registered objects for these interfaces and automatically subscribes them to the appropriate phase of Unity's PlayerLoop.16IInitializable: Any registered class implementing this interface will have its Initialize() method called once at startup, analogous to Awake() or Start(). Our AutomationRunner could implement this to load its rules.ITickable: Any registered class implementing this interface will have its Tick() method called every frame, serving as a direct replacement for Update().33 Our OculusInputService uses this to poll for controller input.IDisposable: Any registered singleton or scoped service implementing this interface will have its Dispose() method called when its LifetimeScope is destroyed (e.g., on scene unload or application quit). This is used for cleanup.Example of AutomationRunner using IInitializable:C#using VContainer.Unity;

public class AutomationRunner : IInitializable
{
    private readonly IRuleLoader _ruleLoader;
    private IReadOnlyList<IAutomation> _automations;
    //... other fields

    public AutomationRunner(IRuleLoader ruleLoader)
    {
        _ruleLoader = ruleLoader;
    }

    // This method will be called automatically by VContainer at startup.
    public void Initialize()
    {
        _automations = _ruleLoader.LoadAllRules();
        InitializeTriggers();
    }

    //... rest of the class
}
This elegant system allows us to write the entirety of our application's logic in pure C# classes, with explicit dependencies and no reliance on MonoBehaviour. The single AppLifetimeScope acts as the sole bridge to the Unity engine, initializing the DI container which then takes over the management and execution of the entire system. This results in a clean, decoupled, and highly performant architecture that fully realizes the user's "no MonoBehaviour" constraint.Section 7: End-to-End Implementation: A Practical VR Use CaseThis final section synthesizes all the preceding architectural concepts into a complete, tangible implementation. We will trace a common VR interactionâ€”grabbing an objectâ€”from its declarative JSON definition through the entire automation engine to its final execution in the Unity scene. This serves as a definitive proof-of-concept, demonstrating the power and practicality of the proposed architecture.7.1 The ScenarioThe goal is to implement a simple, physics-based grab mechanic using our automation system. The desired behavior is as follows:When the user fully presses the right-hand grip button while their hand is physically close to a grabbable cube, the cube becomes parented to the hand. When they release the grip, the cube is detached.This single behavior will require two separate automation rules: one for grabbing and one for releasing.7.2 The JSON Automation RulesThese rules are defined in .json files, which would be loaded by the AutomationRunner at startup.1. grab_object.jsonThis rule handles the attachment logic. It triggers on the grip press, checks for proximity, and then executes the attach action.JSON,
    "conditions":,
    "actions":
  }
]
2. release_object.jsonThis rule handles detaching the object. It triggers on grip release and executes the detach action. Note that it has no conditions; it will always release whatever is attached to the hand.JSON,
    "conditions":,
    "actions":
  }
]
7.3 The C# ImplementationThe following are the key C# classes that implement the components defined in the JSON. This assumes the core AutomationRunner, IInputService, and ActionRegistry from previous sections are already in place.InputStateTrigger.csThis trigger listens to the IInputService and fires when a specific control and state are matched.C#using System;

public class InputStateTrigger : ITrigger
{
    public event Action<IAutomation, TriggerData> OnTriggered;
    private IAutomation _parent;
    private readonly IInputService _inputService;

    // Deserialized from JSON
    public string Control { get; private set; }
    public InputState State { get; private set; }

    public InputStateTrigger(IInputService inputService)
    {
        _inputService = inputService;
    }

    public void Initialize(IAutomation parentAutomation)
    {
        _parent = parentAutomation;
        _inputService.OnInputEvent += OnInputReceived;
    }

    private void OnInputReceived(InputEvent inputEvent)
    {
        if (inputEvent.Control == Control && inputEvent.State == State)
        {
            var data = new TriggerData(_parent.Id, null);
            OnTriggered?.Invoke(_parent, data);
        }
    }
}
ProximityCondition.csThis condition checks if an object with a specific tag is within a certain distance of a source object. It also demonstrates how to pass data forward using the ExecutionContext.C#using UnityEngine;

public class ProximityCondition : ICondition
{
    // Deserialized from JSON
    public string SourceEntityId { get; private set; }
    public string TargetTag { get; private set; }
    public float Distance { get; private set; }
    public string StoreResultAs { get; private set; } // e.g., "nearest_grabbable"

    public async UniTask<bool> EvaluateAsync(ExecutionContext context)
    {
        // In a real implementation, an IEntityResolver service would be used here.
        var source = GameObject.Find(SourceEntityId);
        if (source == null) return false;

        var colliders = Physics.OverlapSphere(source.transform.position, Distance);
        GameObject nearestTarget = null;
        float minDistance = float.MaxValue;

        foreach (var col in colliders)
        {
            if (col.CompareTag(TargetTag))
            {
                float dist = Vector3.Distance(source.transform.position, col.transform.position);
                if (dist < minDistance)
                {
                    minDistance = dist;
                    nearestTarget = col.gameObject;
                }
            }
        }

        if (nearestTarget!= null)
        {
            if (!string.IsNullOrEmpty(StoreResultAs))
            {
                // Store the found object's unique ID in the context's shared data.
                // Actions can then retrieve this value.
                context.SharedData = nearestTarget.name; // Using name as a simple ID
            }
            return true;
        }

        return false;
    }
}
Game Logic Registration (GameLogicInstaller.cs)This is where the game-specific actions are registered with the ActionRegistry. This would be part of a VContainer LifetimeScope.C#public void Install(IContainerBuilder builder)
{
    var registry = builder.Resolve<ActionRegistry>();
    // An IEntityResolver would be a service that maps string IDs to GameObjects.
    var entityResolver = builder.Resolve<IEntityResolver>();

    registry.Register("object.attach", async (context, parameters) =>
    {
        string childId = ResolveParameter(context, parameters["child_entity_id"].Value<string>());
        string parentId = ResolveParameter(context, parameters["parent_entity_id"].Value<string>());

        var child = await entityResolver.FindAsync(childId);
        var parent = await entityResolver.FindAsync(parentId);

        if (child!= null && parent!= null)
        {
            child.transform.SetParent(parent.transform);
            // Optionally reset local position/rotation
            child.transform.localPosition = Vector3.zero;
            child.transform.localRotation = Quaternion.identity;
            
            // Disable physics while attached
            if(child.TryGetComponent<Rigidbody>(out var rb))
            {
                rb.isKinematic = true;
            }
        }
    });

    registry.Register("object.detach_all_children", async (context, parameters) =>
    {
        string parentId = ResolveParameter(context, parameters["parent_entity_id"].Value<string>());
        var parent = await entityResolver.FindAsync(parentId);

        if (parent!= null)
        {
            foreach (Transform child in parent.transform)
            {
                // Re-enable physics
                if(child.TryGetComponent<Rigidbody>(out var rb))
                {
                    rb.isKinematic = false;
                    // Optionally add velocity from hand movement
                }
            }
            parent.transform.DetachChildren();
        }
    });
}

// Helper to resolve context variables like "{context.shared.nearest_grabbable}"
private string ResolveParameter(ExecutionContext context, string paramValue)
{
    if (paramValue.StartsWith("{context.shared.") && paramValue.EndsWith("}"))
    {
        string key = paramValue.Substring(16, paramValue.Length - 17);
        return context.SharedData.TryGetValue(key, out var value)? value.ToString() : null;
    }
    return paramValue;
}
7.4 Walkthrough and DebuggingWith all pieces in place, the flow of execution for a successful grab is as follows:Startup: The AppLifetimeScope initializes VContainer. The AutomationRunner is created and loads grab_object.json and release_object.json. It creates instances of InputStateTrigger, ProximityCondition, and GenericAction for each rule. The triggers subscribe to the OculusInputService.Input: The user presses the right grip button. The OculusInputService.Tick() method detects this change and fires its OnInputEvent.Trigger: The InputStateTrigger for the "Grab Object" rule receives this event, sees that it matches its configuration (Control: "RGrip", State: "began"), and calls OnTriggered, notifying the AutomationRunner.Execution Start: The AutomationRunner.HandleTriggerFired method is invoked. It begins the ExecuteAutomationAsync pipeline for the "VR_GrabObject_RightHand" automation.Condition Evaluation: The runner awaits the ProximityCondition.EvaluateAsync method.The condition performs a Physics.OverlapSphere around the RightHandAnchor.It finds a nearby GameObject with the "Grabbable" tag.It stores the name of this GameObject into context.SharedData["nearest_grabbable"].It returns true.Action Execution: Since the condition passed, the runner proceeds to the actions. It finds the GenericAction with ActionId: "object.attach".The GenericAction.ExecuteAsync method calls _registry.Execute(...).The ActionRegistry finds the delegate registered for "object.attach".The delegate's logic runs. It resolves the child_entity_id by looking up {context.shared.nearest_grabbable} in the ExecutionContext, finding the name of the cube. It resolves the parent_entity_id to "RightHandAnchor".It finds the corresponding GameObjects and performs the transform.SetParent() operation. The cube is now attached to the user's hand.Completion: The ExecuteAutomationAsync method completes, and the runner removes the automation from its list of running instances.This end-to-end example demonstrates a fully decoupled, data-driven, and event-based system. The core engine has no knowledge of grabbing, hands, or cubes; it only orchestrates the execution of generic, interchangeable rules. This powerful abstraction provides a scalable foundation for building arbitrarily complex interaction systems in Unity.